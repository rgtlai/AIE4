{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Retrieval with Langchain Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first set up langsmith, ragus to create test sets and then load the John Wick Data as in the previous notebook. We will also set up QDrant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from uuid import uuid4\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "unique_id = uuid4().hex[0:8]\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Advanced RAG - {unique_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richardlai/miniconda3/envs/AIE4-Week-7/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "critic_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings\n",
    ")\n",
    "\n",
    "distributions = {\n",
    "    simple: 0.5,\n",
    "    multi_context: 0.4,\n",
    "    reasoning: 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "documents = []\n",
    "\n",
    "for i in range(1, 5):\n",
    "  loader = CSVLoader(\n",
    "      file_path=f\"john_wick_{i}.csv\",\n",
    "      metadata_columns=[\"Review_Date\", \"Review_Title\", \"Review_Url\", \"Author\", \"Rating\"]\n",
    "  )\n",
    "\n",
    "  movie_docs = loader.load()\n",
    "  for doc in movie_docs:\n",
    "\n",
    "    # Add the \"Movie Title\" (John Wick 1, 2, ...)\n",
    "    doc.metadata[\"Movie_Title\"] = f\"John Wick {i}\"\n",
    "\n",
    "    # convert \"Rating\" to an `int`, if no rating is provided - assume 0 rating\n",
    "    doc.metadata[\"Rating\"] = int(doc.metadata[\"Rating\"]) if doc.metadata[\"Rating\"] else 0\n",
    "\n",
    "    # newer movies have a more recent \"last_accessed_at\"\n",
    "    doc.metadata[\"last_accessed_at\"] = datetime.now() - timedelta(days=4-i)\n",
    "\n",
    "  documents.extend(movie_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'john_wick_1.csv', 'row': 0, 'Review_Date': '6 May 2015', 'Review_Title': ' Kinetic, concise, and stylish; John Wick kicks ass.\\n', 'Review_Url': '/review/rw3233896/?ref_=tt_urv', 'Author': 'lnvicta', 'Rating': 8, 'Movie_Title': 'John Wick 1', 'last_accessed_at': datetime.datetime(2024, 9, 28, 10, 37, 41, 849349)}, page_content=\": 0\\nReview: The best way I can describe John Wick is to picture Taken but instead of Liam Neeson it's Keanu Reeves and instead of his daughter it's his dog. That's essentially the plot of the movie. John Wick (Reeves) is out to seek revenge on the people who took something he loved from him. It's a beautifully simple premise for an action movie - when action movies get convoluted, they get bad i.e. A Good Day to Die Hard. John Wick gives the viewers what they want: Awesome action, stylish stunts, kinetic chaos, and a relatable hero to tie it all together. John Wick succeeds in its simplicity.\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testset = generator.generate_with_langchain_docs(documents, 20, distributions, with_debugging_logs=False)\n",
    "#import pickle\n",
    "#with open('testset_ragas_john_wick.pkl', 'wb') as file:\n",
    "    #pickle.dump(testset, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is a key element that contributes to the ...</td>\n",
       "      <td>[: 13\\nReview: Following on from two delirious...</td>\n",
       "      <td>The unique appeal of John Wick: Chapter 3 - Pa...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'john_wick_3.csv', 'row': 13, 'Rev...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What challenges does John Wick face after refu...</td>\n",
       "      <td>[: 20\\nReview: After resolving his issues with...</td>\n",
       "      <td>After refusing to help Santino D'Antonio in th...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'john_wick_2.csv', 'row': 20, 'Rev...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are some common cliches associated with t...</td>\n",
       "      <td>[: 13\\nReview: ... slaughtering a line from th...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'john_wick_1.csv', 'row': 13, 'Rev...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What makes John Wick: Chapter 3 - Parabellum s...</td>\n",
       "      <td>[: 13\\nReview: Following on from two delirious...</td>\n",
       "      <td>John Wick: Chapter 3 - Parabellum stands out a...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'john_wick_3.csv', 'row': 13, 'Rev...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What factors contribute to the increase in bod...</td>\n",
       "      <td>[: 14\\nReview: Another significant increase in...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'john_wick_3.csv', 'row': 14, 'Rev...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the significance of practical stunt wo...</td>\n",
       "      <td>[: 22\\nReview: John Wick is one of my favourit...</td>\n",
       "      <td>Practical stunt work in the action movie John ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'john_wick_2.csv', 'row': 22, 'Rev...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What elements of the film John Wick can be des...</td>\n",
       "      <td>[: 9\\nReview: At first glance, John Wick sound...</td>\n",
       "      <td>The film John Wick can be described as having ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'john_wick_1.csv', 'row': 9, 'Revi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How does the level of violence in the third Jo...</td>\n",
       "      <td>[: 20\\nReview: Sadly the third John Wick film ...</td>\n",
       "      <td>The level of violence in the third John Wick f...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'john_wick_3.csv', 'row': 20, 'Rev...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Why does Hollywood focus more on Marvel movies...</td>\n",
       "      <td>[: 10\\nReview: Most American action flicks rel...</td>\n",
       "      <td>Hollywood focuses more on Marvel movies due to...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'john_wick_4.csv', 'row': 10, 'Rev...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Which character in John Wick: Chapter 2 initia...</td>\n",
       "      <td>[: 20\\nReview: After resolving his issues with...</td>\n",
       "      <td>Santino D'Antonio initiates a blood oath with ...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'john_wick_2.csv', 'row': 20, 'Rev...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What fuels John Wick's vengeance and its impac...</td>\n",
       "      <td>[: 5\\nReview: Ultra-violent first entry with l...</td>\n",
       "      <td>John Wick's vengeance is fueled by the death o...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'john_wick_1.csv', 'row': 5, 'Revi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What makes John Wick unique in action genre, w...</td>\n",
       "      <td>[: 8\\nReview: It's hard to find anything bad t...</td>\n",
       "      <td>John Wick is unique in the action genre due to...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'john_wick_1.csv', 'row': 8, 'Revi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What made 'John Wick' stand out?</td>\n",
       "      <td>[: 8\\nReview: It's hard to find anything bad t...</td>\n",
       "      <td>The action in 'John Wick' is beautifully chore...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'john_wick_1.csv', 'row': 8, 'Revi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What key element makes action movies successfu...</td>\n",
       "      <td>[: 22\\nReview: Lets contemplate about componen...</td>\n",
       "      <td>The key elements that make action movies succe...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'john_wick_3.csv', 'row': 22, 'Rev...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>How does stunt work affect action in John Wick?</td>\n",
       "      <td>[: 22\\nReview: John Wick is one of my favourit...</td>\n",
       "      <td>The practical stunt work in John Wick enhances...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'john_wick_2.csv', 'row': 22, 'Rev...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Who stars in TAKEN and JOHN WICK?</td>\n",
       "      <td>[: 11\\nReview: JOHN WICK is a rare example of ...</td>\n",
       "      <td>Liam Neeson stars in TAKEN and Keanu Reeves st...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'john_wick_1.csv', 'row': 11, 'Rev...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>How does John Wick's quest for vengeance compa...</td>\n",
       "      <td>[: 0\\nReview: The best way I can describe John...</td>\n",
       "      <td>John Wick's quest for vengeance in the movie i...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'john_wick_1.csv', 'row': 0, 'Revi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   What is a key element that contributes to the ...   \n",
       "1   What challenges does John Wick face after refu...   \n",
       "2   What are some common cliches associated with t...   \n",
       "3   What makes John Wick: Chapter 3 - Parabellum s...   \n",
       "4   What factors contribute to the increase in bod...   \n",
       "5   What is the significance of practical stunt wo...   \n",
       "6   What elements of the film John Wick can be des...   \n",
       "7   How does the level of violence in the third Jo...   \n",
       "8   Why does Hollywood focus more on Marvel movies...   \n",
       "9   Which character in John Wick: Chapter 2 initia...   \n",
       "10  What fuels John Wick's vengeance and its impac...   \n",
       "11  What makes John Wick unique in action genre, w...   \n",
       "12                   What made 'John Wick' stand out?   \n",
       "13  What key element makes action movies successfu...   \n",
       "14    How does stunt work affect action in John Wick?   \n",
       "15                  Who stars in TAKEN and JOHN WICK?   \n",
       "16  How does John Wick's quest for vengeance compa...   \n",
       "\n",
       "                                             contexts  \\\n",
       "0   [: 13\\nReview: Following on from two delirious...   \n",
       "1   [: 20\\nReview: After resolving his issues with...   \n",
       "2   [: 13\\nReview: ... slaughtering a line from th...   \n",
       "3   [: 13\\nReview: Following on from two delirious...   \n",
       "4   [: 14\\nReview: Another significant increase in...   \n",
       "5   [: 22\\nReview: John Wick is one of my favourit...   \n",
       "6   [: 9\\nReview: At first glance, John Wick sound...   \n",
       "7   [: 20\\nReview: Sadly the third John Wick film ...   \n",
       "8   [: 10\\nReview: Most American action flicks rel...   \n",
       "9   [: 20\\nReview: After resolving his issues with...   \n",
       "10  [: 5\\nReview: Ultra-violent first entry with l...   \n",
       "11  [: 8\\nReview: It's hard to find anything bad t...   \n",
       "12  [: 8\\nReview: It's hard to find anything bad t...   \n",
       "13  [: 22\\nReview: Lets contemplate about componen...   \n",
       "14  [: 22\\nReview: John Wick is one of my favourit...   \n",
       "15  [: 11\\nReview: JOHN WICK is a rare example of ...   \n",
       "16  [: 0\\nReview: The best way I can describe John...   \n",
       "\n",
       "                                         ground_truth evolution_type  \\\n",
       "0   The unique appeal of John Wick: Chapter 3 - Pa...         simple   \n",
       "1   After refusing to help Santino D'Antonio in th...         simple   \n",
       "2   The answer to given question is not present in...         simple   \n",
       "3   John Wick: Chapter 3 - Parabellum stands out a...         simple   \n",
       "4   The answer to given question is not present in...         simple   \n",
       "5   Practical stunt work in the action movie John ...         simple   \n",
       "6   The film John Wick can be described as having ...         simple   \n",
       "7   The level of violence in the third John Wick f...         simple   \n",
       "8   Hollywood focuses more on Marvel movies due to...         simple   \n",
       "9   Santino D'Antonio initiates a blood oath with ...  multi_context   \n",
       "10  John Wick's vengeance is fueled by the death o...  multi_context   \n",
       "11  John Wick is unique in the action genre due to...  multi_context   \n",
       "12  The action in 'John Wick' is beautifully chore...  multi_context   \n",
       "13  The key elements that make action movies succe...  multi_context   \n",
       "14  The practical stunt work in John Wick enhances...  multi_context   \n",
       "15  Liam Neeson stars in TAKEN and Keanu Reeves st...  multi_context   \n",
       "16  John Wick's quest for vengeance in the movie i...      reasoning   \n",
       "\n",
       "                                             metadata  episode_done  \n",
       "0   [{'source': 'john_wick_3.csv', 'row': 13, 'Rev...          True  \n",
       "1   [{'source': 'john_wick_2.csv', 'row': 20, 'Rev...          True  \n",
       "2   [{'source': 'john_wick_1.csv', 'row': 13, 'Rev...          True  \n",
       "3   [{'source': 'john_wick_3.csv', 'row': 13, 'Rev...          True  \n",
       "4   [{'source': 'john_wick_3.csv', 'row': 14, 'Rev...          True  \n",
       "5   [{'source': 'john_wick_2.csv', 'row': 22, 'Rev...          True  \n",
       "6   [{'source': 'john_wick_1.csv', 'row': 9, 'Revi...          True  \n",
       "7   [{'source': 'john_wick_3.csv', 'row': 20, 'Rev...          True  \n",
       "8   [{'source': 'john_wick_4.csv', 'row': 10, 'Rev...          True  \n",
       "9   [{'source': 'john_wick_2.csv', 'row': 20, 'Rev...          True  \n",
       "10  [{'source': 'john_wick_1.csv', 'row': 5, 'Revi...          True  \n",
       "11  [{'source': 'john_wick_1.csv', 'row': 8, 'Revi...          True  \n",
       "12  [{'source': 'john_wick_1.csv', 'row': 8, 'Revi...          True  \n",
       "13  [{'source': 'john_wick_3.csv', 'row': 22, 'Rev...          True  \n",
       "14  [{'source': 'john_wick_2.csv', 'row': 22, 'Rev...          True  \n",
       "15  [{'source': 'john_wick_1.csv', 'row': 11, 'Rev...          True  \n",
       "16  [{'source': 'john_wick_1.csv', 'row': 0, 'Revi...          True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('testset_ragas_john_wick.pkl', 'rb') as file:\n",
    "    testset = pickle.load(file)\n",
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are retrievers for Naive, BM25 and Multi-Query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores  import Qdrant\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "#from langchain_cohere import CohereRerank\n",
    "chat_model = ChatOpenAI()\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    documents,\n",
    "    embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"johnwick_collection\"\n",
    ")\n",
    "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})\n",
    "bm25_retriever = BM25Retriever.from_documents(documents)\n",
    "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=naive_retriever, llm=chat_model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is for Parent Document Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "parent_docs = documents\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)\n",
    "\n",
    "client = QdrantClient(location=\":memory:\")\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"full_documents\",\n",
    "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
    ")\n",
    "\n",
    "parent_document_vectorstore = Qdrant(\n",
    "    collection_name=\"full_documents\", \n",
    "    embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"), \n",
    "    client=client\n",
    ")\n",
    "\n",
    "store = InMemoryStore()\n",
    "\n",
    "parent_document_retriever = ParentDocumentRetriever(\n",
    "    vectorstore = parent_document_vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    ")\n",
    "\n",
    "parent_document_retriever.add_documents(parent_docs, ids=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is Contextual Compression (Using Reranking). Not sure why cohere is no longer working, probably due to library conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "no validator found for <class 'pydantic.types.SecretStr'>, see `arbitrary_types_allowed` in Config",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontextual_compression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ContextualCompressionRetriever\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_cohere\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CohereRerank\n",
      "File \u001b[0;32m~/miniconda3/envs/AIE4-Week-7/lib/python3.11/site-packages/langchain_cohere/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_cohere\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummarize\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummarize_chain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_summarize_chain\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_cohere\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatCohere\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_cohere\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcohere_agent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_cohere_tools_agent\n",
      "File \u001b[0;32m~/miniconda3/envs/AIE4-Week-7/lib/python3.11/site-packages/langchain_cohere/chains/summarize/summarize_chain.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RunnableLambda, RunnableSerializable\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_cohere\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummarize\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RAG_SUMMARIZATION_PREAMBLE\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_cohere\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatCohere\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_summarize_prompt\u001b[39m(\n\u001b[1;32m     22\u001b[0m     prompt_message: BaseMessage \u001b[38;5;241m=\u001b[39m HumanMessage(\n\u001b[1;32m     23\u001b[0m         content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease summarize the documents in a concise manner.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m     ),\n\u001b[1;32m     25\u001b[0m     extra_prompt_messages: List[BaseMessagePromptTemplate] \u001b[38;5;241m=\u001b[39m [],\n\u001b[1;32m     26\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatPromptTemplate:\n\u001b[1;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create prompt for this agent.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m        system_message: Message to use as the system message that will be the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m        A prompt template to pass into this agent.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/AIE4-Week-7/lib/python3.11/site-packages/langchain_cohere/chat_models.py:58\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel, ConfigDict, PrivateAttr\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_cohere\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcohere_agent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     55\u001b[0m     _convert_to_cohere_tool,\n\u001b[1;32m     56\u001b[0m     _format_to_cohere_tools,\n\u001b[1;32m     57\u001b[0m )\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_cohere\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseCohere\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_cohere\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreact_multi_hop\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_to_documents\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_message_to_cohere_tool_results\u001b[39m(\n\u001b[1;32m     63\u001b[0m     messages: List[BaseMessage], tool_message_index: \u001b[38;5;28mint\u001b[39m\n\u001b[1;32m     64\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n",
      "File \u001b[0;32m~/miniconda3/envs/AIE4-Week-7/lib/python3.11/site-packages/langchain_cohere/llms.py:56\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m llm\u001b[38;5;241m.\u001b[39masync_client\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _completion_with_retry(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mBaseCohere\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mSerializable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"Base class for Cohere models.\"\"\"\u001b[39;49;00m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mAny\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#: :meta private:\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/AIE4-Week-7/lib/python3.11/site-packages/pydantic/v1/main.py:197\u001b[0m, in \u001b[0;36mModelMetaclass.__new__\u001b[0;34m(mcs, name, bases, namespace, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    190\u001b[0m         is_untouched(value)\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m ann_type \u001b[38;5;241m!=\u001b[39m PyObject\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m     ):\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m     fields[ann_name] \u001b[38;5;241m=\u001b[39m \u001b[43mModelField\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mann_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mannotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mann_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_validators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_validators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mann_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ann_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m namespace \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39munderscore_attrs_are_private:\n\u001b[1;32m    205\u001b[0m     private_attributes[ann_name] \u001b[38;5;241m=\u001b[39m PrivateAttr()\n",
      "File \u001b[0;32m~/miniconda3/envs/AIE4-Week-7/lib/python3.11/site-packages/pydantic/v1/fields.py:504\u001b[0m, in \u001b[0;36mModelField.infer\u001b[0;34m(cls, name, value, annotation, class_validators, config)\u001b[0m\n\u001b[1;32m    501\u001b[0m     required \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    502\u001b[0m annotation \u001b[38;5;241m=\u001b[39m get_annotation_from_field_info(annotation, field_info, name, config\u001b[38;5;241m.\u001b[39mvalidate_assignment)\n\u001b[0;32m--> 504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtype_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43malias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_validators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_validators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequired\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequired\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfield_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/AIE4-Week-7/lib/python3.11/site-packages/pydantic/v1/fields.py:434\u001b[0m, in \u001b[0;36mModelField.__init__\u001b[0;34m(self, name, type_, class_validators, model_config, default, default_factory, required, final, alias, field_info)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m SHAPE_SINGLETON\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mprepare_field(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 434\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/AIE4-Week-7/lib/python3.11/site-packages/pydantic/v1/fields.py:555\u001b[0m, in \u001b[0;36mModelField.prepare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault \u001b[38;5;129;01mis\u001b[39;00m Undefined \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 555\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopulate_validators\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/AIE4-Week-7/lib/python3.11/site-packages/pydantic/v1/fields.py:829\u001b[0m, in \u001b[0;36mModelField.populate_validators\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msub_fields \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m SHAPE_GENERIC:\n\u001b[1;32m    826\u001b[0m     get_validators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__get_validators__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    827\u001b[0m     v_funcs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    828\u001b[0m         \u001b[38;5;241m*\u001b[39m[v\u001b[38;5;241m.\u001b[39mfunc \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m class_validators_ \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39meach_item \u001b[38;5;129;01mand\u001b[39;00m v\u001b[38;5;241m.\u001b[39mpre],\n\u001b[0;32m--> 829\u001b[0m         \u001b[38;5;241m*\u001b[39m(get_validators() \u001b[38;5;28;01mif\u001b[39;00m get_validators \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(find_validators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config))),\n\u001b[1;32m    830\u001b[0m         \u001b[38;5;241m*\u001b[39m[v\u001b[38;5;241m.\u001b[39mfunc \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m class_validators_ \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39meach_item \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mpre],\n\u001b[1;32m    831\u001b[0m     )\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidators \u001b[38;5;241m=\u001b[39m prep_validators(v_funcs)\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_validators \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/AIE4-Week-7/lib/python3.11/site-packages/pydantic/v1/validators.py:765\u001b[0m, in \u001b[0;36mfind_validators\u001b[0;34m(type_, config)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m make_arbitrary_type_validator(type_)\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno validator found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, see `arbitrary_types_allowed` in Config\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: no validator found for <class 'pydantic.types.SecretStr'>, see `arbitrary_types_allowed` in Config"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain_cohere import CohereRerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the setup for Ensemble retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever,  multi_query_retriever]\n",
    "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=retriever_list, weights=equal_weighting\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally there is a Semantic chunker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "semantic_chunker = SemanticChunker(\n",
    "    embeddings,\n",
    "    breakpoint_threshold_type=\"percentile\"\n",
    ")\n",
    "semantic_documents = semantic_chunker.split_documents(documents)\n",
    "\n",
    "semantic_vectorstore = Qdrant.from_documents(\n",
    "    semantic_documents,\n",
    "    embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"johnwick_collection_semantic\"\n",
    ")\n",
    "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_TEMPLATE = \"\"\"\\\n",
    "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
    "\n",
    "If you do not know the answer, or are unsure, say you don't know.\n",
    "\n",
    "Query:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)\n",
    "def create_chain(retriever):\n",
    "    return ({\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    answer_correctness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "test_df = testset.to_pandas()\n",
    "test_questions = test_df[\"question\"].values.tolist()\n",
    "test_groundtruths = test_df[\"ground_truth\"].values.tolist()\n",
    "\n",
    "metrics = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_correctness,\n",
    "]\n",
    "\n",
    "def run_evaluation(retrieval_chain):\n",
    "    answers = []\n",
    "    contexts = []\n",
    "\n",
    "    for question in test_questions:\n",
    "        response = retrieval_chain.invoke({\"question\" : question})\n",
    "        answers.append(response[\"response\"].content)\n",
    "        contexts.append([context.page_content for context in response[\"context\"]])\n",
    "    response_dataset = Dataset.from_dict({\n",
    "        \"question\" : test_questions,\n",
    "        \"answer\" : answers,\n",
    "        \"contexts\" : contexts,\n",
    "        \"ground_truth\" : test_groundtruths\n",
    "    })\n",
    "    return evaluate(response_dataset, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 85/85 [00:42<00:00,  2.01it/s]\n",
      "Evaluating: 100%|██████████| 85/85 [00:33<00:00,  2.57it/s]\n",
      "Evaluating: 100%|██████████| 85/85 [00:53<00:00,  1.58it/s]\n",
      "Evaluating: 100%|██████████| 85/85 [00:29<00:00,  2.87it/s]\n",
      "Evaluating: 100%|██████████| 85/85 [01:01<00:00,  1.38it/s]\n",
      "Evaluating: 100%|██████████| 85/85 [00:49<00:00,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "mapper = {\n",
    "    \"naive_retriever\": naive_retriever,\n",
    "    \"bm25_retriever\": bm25_retriever,\n",
    "    \"multi_query_retriever\": multi_query_retriever,\n",
    "    \"parent_document_retriever\": parent_document_retriever,\n",
    "    \"ensemble_retriever\": ensemble_retriever,\n",
    "    \"semantic_retriever\": semantic_retriever\n",
    "}\n",
    " \n",
    "def run_all():\n",
    "    output = {}\n",
    "    for ret in mapper:\n",
    "        unique_id = uuid4().hex[0:8]\n",
    "        @traceable(\n",
    "                run_type=\"llm\",\n",
    "                name=\"OpenAI Call Decorator\",\n",
    "                project_name=f\"{ret} - {unique_id}\"\n",
    "        )\n",
    "        def _run_eval(retriever):\n",
    "            return run_evaluation(retriever)\n",
    "\n",
    "        output[ret] = _run_eval(create_chain(mapper[ret]))\n",
    "    return output\n",
    "        \n",
    "output = run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'naive_retriever': {'faithfulness': 0.7670, 'answer_relevancy': 0.9133, 'context_recall': 0.9020, 'context_precision': 0.7678, 'answer_correctness': 0.6934},\n",
       " 'bm25_retriever': {'faithfulness': 0.7085, 'answer_relevancy': 0.8600, 'context_recall': 0.8431, 'context_precision': 0.7010, 'answer_correctness': 0.6436},\n",
       " 'multi_query_retriever': {'faithfulness': 0.7107, 'answer_relevancy': 0.8506, 'context_recall': 0.9314, 'context_precision': 0.7168, 'answer_correctness': 0.6541},\n",
       " 'parent_document_retriever': {'faithfulness': 0.6672, 'answer_relevancy': 0.9118, 'context_recall': 0.7353, 'context_precision': 0.7353, 'answer_correctness': 0.7265},\n",
       " 'ensemble_retriever': {'faithfulness': 0.8111, 'answer_relevancy': 0.9199, 'context_recall': 0.9020, 'context_precision': 0.7000, 'answer_correctness': 0.7352},\n",
       " 'semenatic_retriever': {'faithfulness': 0.8436, 'answer_relevancy': 0.9704, 'context_recall': 0.8784, 'context_precision': 0.7038, 'answer_correctness': 0.6228}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Naive</th>\n",
       "      <th>BM25</th>\n",
       "      <th>MultiQuery</th>\n",
       "      <th>ParentDoc</th>\n",
       "      <th>Ensemble</th>\n",
       "      <th>Semantic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faithfulness</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.708497</td>\n",
       "      <td>0.710668</td>\n",
       "      <td>0.667157</td>\n",
       "      <td>0.811091</td>\n",
       "      <td>0.843604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>answer_relevancy</td>\n",
       "      <td>0.913262</td>\n",
       "      <td>0.860031</td>\n",
       "      <td>0.850625</td>\n",
       "      <td>0.911831</td>\n",
       "      <td>0.919855</td>\n",
       "      <td>0.970443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>context_recall</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.878431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>context_precision</td>\n",
       "      <td>0.767777</td>\n",
       "      <td>0.700980</td>\n",
       "      <td>0.716796</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.699976</td>\n",
       "      <td>0.703841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer_correctness</td>\n",
       "      <td>0.693357</td>\n",
       "      <td>0.643573</td>\n",
       "      <td>0.654057</td>\n",
       "      <td>0.726511</td>\n",
       "      <td>0.735202</td>\n",
       "      <td>0.622808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Metric     Naive      BM25  MultiQuery  ParentDoc  Ensemble  \\\n",
       "0        faithfulness  0.766993  0.708497    0.710668   0.667157  0.811091   \n",
       "1    answer_relevancy  0.913262  0.860031    0.850625   0.911831  0.919855   \n",
       "2      context_recall  0.901961  0.843137    0.931373   0.735294  0.901961   \n",
       "3   context_precision  0.767777  0.700980    0.716796   0.735294  0.699976   \n",
       "4  answer_correctness  0.693357  0.643573    0.654057   0.726511  0.735202   \n",
       "\n",
       "   Semantic  \n",
       "0  0.843604  \n",
       "1  0.970443  \n",
       "2  0.878431  \n",
       "3  0.703841  \n",
       "4  0.622808  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_naive = pd.DataFrame(list(output[\"naive_retriever\"].items()), columns=['Metric', 'Naive'])\n",
    "df_bm25 = pd.DataFrame(list(output[\"bm25_retriever\"].items()), columns=['Metric', 'BM25'])\n",
    "df_multi_query = pd.DataFrame(list(output[\"multi_query_retriever\"].items()), columns=['Metric','MultiQuery'])\n",
    "df_parent= pd.DataFrame(list(output[\"parent_document_retriever\"].items()), columns=['Metric', 'ParentDoc'])\n",
    "df_ensemble = pd.DataFrame(list(output[\"ensemble_retriever\"].items()), columns=['Metric', 'Ensemble'])\n",
    "df_semantic = pd.DataFrame(list(output[\"semenatic_retriever\"].items()), columns=['Metric', 'Semantic'])\n",
    "df_merged = df_naive.merge(df_bm25, on='Metric').merge(df_multi_query, on='Metric').merge(df_parent, on='Metric')\n",
    "df_merged = df_merged.merge(df_ensemble, on='Metric').merge(df_semantic, on='Metric')\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It looks semantic chunking results in the best answer relevancy while the ensemble retriever appears to have the best answer correctness. Overrall semantic does well. MultiQuery does really well con context recall.\n",
    "\n",
    " As for cost one can look at the Langsmith traces. Of course the ensemble would cost the most as it makes multiple llm calls for each data point. Parent Document and MB25 are the cheapest but BM25 is not recommended due to performance.\n",
    " \n",
    "![image](langsmith.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIE4-Week-7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
